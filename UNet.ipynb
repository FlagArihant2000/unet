{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk0LPLD2zy8K",
        "outputId": "9ab528cc-9c6b-4dc4-dba0-d1aef55b1e9a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giyIa8LsT_C1",
        "outputId": "4fa2d233-d8ae-4374-9ba2-3a1bf6248d99"
      },
      "source": [
        "%cd '/content/drive/My Drive/SemSeg'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/SemSeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVdRhU50k-fI"
      },
      "source": [
        "#!unzip archive.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTVs6DGcz7LX"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E6StwkU0Myy"
      },
      "source": [
        "#def c2g(colors):\n",
        "#  cn = np.reshape(colors, (1,1,3))\n",
        "#  cn = cv2.cvtColor(cn, cv2.COLOR_BGR2GRAY)\n",
        "#  return cn\n",
        "# Pixel classes\n",
        "colors = np.array([[0,0,0], [111,74,0], [81,0,81], [128,64,128], [244, 35, 232]\n",
        "                   ,[250, 170, 160], [230, 150, 140], [70,70,70], [102,102, 156]\n",
        "                   , [190, 153, 153], [180, 165, 180], [150, 100, 100]\n",
        "                   , [150, 120, 90], [153, 153, 153], [250, 170, 30], [220, 220, 0]\n",
        "                   , [107, 142, 35], [152, 251, 152], [70, 130, 180], [220, 20, 60]\n",
        "                   , [255, 0, 0], [0, 0, 142], [0, 0, 70], [0, 60, 100], [0, 0, 90]\n",
        "                   , [0, 0, 110], [0, 80, 100], [0, 0, 230], [119, 11, 32], [0, 0, 142]], dtype = np.uint8)\n",
        "def c2g(colors):\n",
        "  c2g = []\n",
        "  for color in colors:\n",
        "    color = np.reshape(color, (1,1,3))\n",
        "    gray = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)\n",
        "    c2g.append(gray)\n",
        "  return c2g\n",
        "colors = c2g(colors)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fm8CF13A0J4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00e12d21-6c16-4cf2-dd40-2c3ff7a36556"
      },
      "source": [
        "colors"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[0]], dtype=uint8),\n",
              " array([[56]], dtype=uint8),\n",
              " array([[33]], dtype=uint8),\n",
              " array([[90]], dtype=uint8),\n",
              " array([[118]], dtype=uint8),\n",
              " array([[176]], dtype=uint8),\n",
              " array([[156]], dtype=uint8),\n",
              " array([[70]], dtype=uint8),\n",
              " array([[118]], dtype=uint8),\n",
              " array([[157]], dtype=uint8),\n",
              " array([[171]], dtype=uint8),\n",
              " array([[106]], dtype=uint8),\n",
              " array([[114]], dtype=uint8),\n",
              " array([[153]], dtype=uint8),\n",
              " array([[137]], dtype=uint8),\n",
              " array([[154]], dtype=uint8),\n",
              " array([[106]], dtype=uint8),\n",
              " array([[210]], dtype=uint8),\n",
              " array([[138]], dtype=uint8),\n",
              " array([[55]], dtype=uint8),\n",
              " array([[29]], dtype=uint8),\n",
              " array([[42]], dtype=uint8),\n",
              " array([[21]], dtype=uint8),\n",
              " array([[65]], dtype=uint8),\n",
              " array([[27]], dtype=uint8),\n",
              " array([[33]], dtype=uint8),\n",
              " array([[77]], dtype=uint8),\n",
              " array([[69]], dtype=uint8),\n",
              " array([[30]], dtype=uint8),\n",
              " array([[42]], dtype=uint8)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPW1D0Rp0dzQ"
      },
      "source": [
        "# Perform Data Loading\n",
        "\n",
        "transform_img = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n",
        "transform_label = transforms.Compose([transforms.ToTensor()])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuFr_Jqo1sil"
      },
      "source": [
        "def load_img(directory, gray, input):\n",
        "  images = []\n",
        "  for img in os.listdir(directory):\n",
        "    img = cv2.imread(os.path.join(directory, img))\n",
        "    if input:\n",
        "      img = cv2.resize(img, (572, 572), interpolation = cv2.INTER_AREA)\n",
        "    else:\n",
        "      img = cv2.resize(img, (388, 388), interpolation = cv2.INTER_AREA)\n",
        "    if gray:\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    images.append(img)\n",
        "  return images\n",
        "\n",
        "def class_pix(labelimg, colors):\n",
        "  class_pix = np.ones([388,388,1], dtype = int)\n",
        "  for index, c in enumerate(colors):\n",
        "    class_pix[labelimg == c] = index\n",
        "  return class_pix\n",
        "\n",
        "def label(imagelist):\n",
        "  images = []\n",
        "  for img in imagelist:\n",
        "    images.append(class_pix(img, colors))\n",
        "  return images"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xW6steF1dQ9"
      },
      "source": [
        "class train(data.Dataset):\n",
        "  def __init__(self, transform = None, imgdir = None, labeldir = None, transformlabel = None):\n",
        "    self.train_img = load_img(imgdir, gray = False, input = True)\n",
        "    self.transform = transform\n",
        "    self.transformlabel = transformlabel\n",
        "    self.train_label = label(load_img(labeldir, gray = True, input = False))\n",
        "  def __len__(self):\n",
        "    return len(self.train_img)\n",
        "  def __getitem__(self, index):\n",
        "    img = self.transform(self.train_img[index])\n",
        "    label = self.transformlabel(self.train_label[index])\n",
        "    return img, label\n",
        "\n",
        "class validation(data.Dataset):\n",
        "  def __init__(self, transform = None, imgdir = None, labeldir = None, transformlabel = None):\n",
        "    self.train_img = load_img(imgdir, gray = False, input = True)\n",
        "    self.transform = transform\n",
        "    self.transformlabel = transformlabel\n",
        "    self.train_label = label(load_img(labeldir, gray = True, input = False))\n",
        "  def __len__(self):\n",
        "    return len(self.train_img)\n",
        "  def __getitem__(self, index):\n",
        "    img = self.transform(self.train_img[index])\n",
        "    label = self.transformlabel(self.train_label[index])\n",
        "    return img, label\n",
        "\n",
        "class test(data.Dataset):\n",
        "  def __init__(self, transform = None, imgdir = None, labeldir = None, transformlabel = None):\n",
        "    self.train_img = load_img(imgdir, gray = False, input = True)\n",
        "    self.transform = transform\n",
        "    self.transformlabel = transformlabel\n",
        "    self.train_label = label(load_img(labeldir, gray = True, input = False))\n",
        "  def __len__(self):\n",
        "    return len(self.train_img)\n",
        "  def __getitem__(self, index):\n",
        "    img = self.transform(self.train_img[index])\n",
        "    label = self.transformlabel(self.train_label[index])\n",
        "    return img, label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WD3L9I1ITtUD",
        "outputId": "a27c82e2-d88e-4a75-f077-dd54dcc72fa8"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/SemSeg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGs8eWZUT6DJ"
      },
      "source": [
        "trainset = train(transform_img, os.path.join(os.getcwd(),'CamVid/train'),\n",
        "                 os.path.join(os.getcwd(), 'CamVid/train_labels'),transform_label)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6cW427ImSA_"
      },
      "source": [
        "valset = validation(transform_img, os.path.join(os.getcwd(),'CamVid/val'),\n",
        "                 os.path.join(os.getcwd(), 'CamVid/val_labels'),transform_label)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej601bStmXDf"
      },
      "source": [
        "testset = test(transform_img, os.path.join(os.getcwd(),'CamVid/test'),\n",
        "                 os.path.join(os.getcwd(), 'CamVid/test_labels'),transform_label)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdAUE6NFmXpv"
      },
      "source": [
        "train_loader = data.DataLoader(trainset, batch_size = 1, shuffle = True, num_workers = 4)\n",
        "val_loader = data.DataLoader(valset, batch_size = 1, shuffle = True, num_workers = 4)\n",
        "test_loader = data.DataLoader(testset, batch_size = 1, shuffle = True, num_workers = 4)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1lF7PBInJcc"
      },
      "source": [
        "# Defining U - Net Architecture\n",
        "def double_conv(in_channel, out_channel):\n",
        "  conv = nn.Sequential(\n",
        "      nn.Conv2d(in_channel, out_channel, kernel_size = 3),\n",
        "      nn.ReLU(inplace = True),\n",
        "      nn.Conv2d(out_channel, out_channel, kernel_size = 3),\n",
        "      nn.ReLU(inplace = True)\n",
        "  )\n",
        "  return conv\n",
        "\n",
        "def crop_img(original, target):\n",
        "  target_size = target.size()[2]\n",
        "  original_size = original.size()[2]\n",
        "  delta = original_size - target_size\n",
        "  delta = delta // 2\n",
        "  return original[:, :, delta:original_size - delta, delta:original_size - delta]\n",
        "\n",
        "class UNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(UNet, self).__init__()\n",
        "    self.max_pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    self.down_conv_1 = double_conv(3, 64)\n",
        "    self.down_conv_2 = double_conv(64, 128)\n",
        "    self.down_conv_3 = double_conv(128, 256)\n",
        "    self.down_conv_4 = double_conv(256, 512)\n",
        "    self.down_conv_5 = double_conv(512, 1024)\n",
        "\n",
        "    self.up_trans_1 = nn.ConvTranspose2d(1024, 512, kernel_size = 2, stride = 2)\n",
        "    self.up_conv_1 = double_conv(1024, 512)\n",
        "\n",
        "    self.up_trans_2 = nn.ConvTranspose2d(512, 256, kernel_size = 2, stride = 2)\n",
        "    self.up_conv_2 = double_conv(512, 256)\n",
        "\n",
        "    self.up_trans_3 = nn.ConvTranspose2d(256, 128, kernel_size = 2, stride = 2)\n",
        "    self.up_conv_3 = double_conv(256, 128)\n",
        "\n",
        "    self.up_trans_4 = nn.ConvTranspose2d(128, 64, kernel_size = 2, stride = 2)\n",
        "    self.up_conv_4 = double_conv(128, 64)\n",
        "\n",
        "    self.out = nn.Conv2d(64, 32, kernel_size = 1)\n",
        "\n",
        "  \n",
        "  def forward(self, image):\n",
        "    # Batch size, channel, height, width\n",
        "    # Encoder\n",
        "    x1 = self.down_conv_1(image)\n",
        "    x2 = self.max_pool(x1)\n",
        "\n",
        "    x3 = self.down_conv_2(x2)\n",
        "    x4 = self.max_pool(x3)\n",
        "\n",
        "    x5 = self.down_conv_3(x4)\n",
        "    x6 = self.max_pool(x5)\n",
        "\n",
        "    x7 = self.down_conv_4(x6)\n",
        "    x8 = self.max_pool(x7)\n",
        "\n",
        "    x9 = self.down_conv_5(x8)\n",
        "\n",
        "    # Decoder\n",
        "    x = self.up_trans_1(x9)\n",
        "    y = crop_img(x7, x)\n",
        "    x = self.up_conv_1(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.up_trans_2(x)\n",
        "    y = crop_img(x5, x)\n",
        "    x = self.up_conv_2(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.up_trans_3(x)\n",
        "    y = crop_img(x3, x)\n",
        "    x = self.up_conv_3(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.up_trans_4(x)\n",
        "    y = crop_img(x1, x)\n",
        "    x = self.up_conv_4(torch.cat([x, y], 1))\n",
        "\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq3HDSeSnSls",
        "outputId": "8fd578ea-05bd-488f-9394-40b584d1644d"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xq2lB-VdnX_R",
        "outputId": "f9cd7e06-f4c0-429c-af92-f79f711ad360"
      },
      "source": [
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W56AVC7bn-9h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2413c42-78d5-48c2-b7f5-81f5ccdcc486"
      },
      "source": [
        "UNET = UNet()\n",
        "UNET.to(device)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "UNet(\n",
              "  (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (down_conv_1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_conv_2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_conv_3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_conv_4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (down_conv_5): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_trans_1): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_conv_1): Sequential(\n",
              "    (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_trans_2): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_conv_2): Sequential(\n",
              "    (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_trans_3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_conv_3): Sequential(\n",
              "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (up_trans_4): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
              "  (up_conv_4): Sequential(\n",
              "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "  )\n",
              "  (out): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92zv99wCnYqG"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(UNET.parameters(), lr = 0.001, betas = (0.9, 0.999), eps = 1e-08, weight_decay = 0, amsgrad = False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vV3oC95hLy-"
      },
      "source": [
        "#import os\n",
        "#os._exit(00)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYtGnX0KzhrU"
      },
      "source": [
        "#UNET = torch.load(os.path.join(os.getcwd(), unet20.pth))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ie1hbAZv9nnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b5fac0-28f0-40dc-a356-69114cbeb2ec"
      },
      "source": [
        "train_loss = []\n",
        "val_loss = []\n",
        "epochs = 100\n",
        "for ep in range(epochs):\n",
        "  UNET.train()\n",
        "  running_loss = 0.0\n",
        "  counter = 0\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    if labels.size() == torch.Size([1, 1, 388, 388]):\n",
        "      labels = labels.reshape(1, 388, 388)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = UNET(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss = running_loss + loss.item()\n",
        "    counter = counter + 1\n",
        "  epoch_loss = running_loss/counter\n",
        "  print('Epoch {}/{}, {} Loss: {:.4f}'.format(ep, epochs, 'Training', epoch_loss))\n",
        "  train_loss = train_loss + [epoch_loss]\n",
        "  UNET.eval()\n",
        "  running_loss = 0.0\n",
        "  counter = 0\n",
        "  for i, data in enumerate(val_loader):\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    if labels.size() == torch.Size([1, 1, 388, 388]):\n",
        "      labels = labels.reshape(1, 388, 388)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = UNET(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss = running_loss + loss.item()\n",
        "    counter = counter + 1\n",
        "  epoch_loss = running_loss/counter\n",
        "  print('Epoch {}/{}, {} Loss: {:.4f}'.format(ep, epochs, 'Validation', epoch_loss))\n",
        "  val_loss = val_loss + [epoch_loss]\n",
        "  if ep%10 == 0:\n",
        "    print(\"Saving Model after epoch {}\".format(ep))\n",
        "    torch.save(UNET.state_dict(), os.path.join(os.getcwd(), 'unet{}.pth'.format(ep)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/100, Training Loss: 0.8068\n",
            "Epoch 0/100, Validation Loss: 0.6059\n",
            "Saving Model after epoch 0\n",
            "Epoch 1/100, Training Loss: 0.5924\n",
            "Epoch 1/100, Validation Loss: 0.5862\n",
            "Epoch 2/100, Training Loss: 1.2909\n",
            "Epoch 2/100, Validation Loss: 0.7040\n",
            "Epoch 3/100, Training Loss: 0.6021\n",
            "Epoch 3/100, Validation Loss: 0.5558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rWInsUY203c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}